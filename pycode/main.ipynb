{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#|code-fold: true\n",
    "#|output: false\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import platform\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, WeightedRandomSampler, SubsetRandomSampler\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, ToPILImage, RandomHorizontalFlip, Resize\n",
    "\n",
    "from step_by_step import StepByStep\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have accumulated labels in the `data\\all_labels` folder. We need to:\n",
    "- load all of them into NCWH tensors\n",
    "- split them into train and valid (test labels will be separate), \n",
    "- create temporary Datasets and normalizer\n",
    "- create real Datasets and DataLoaders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a `x_tensor/y_tensor` from all_labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path('.').resolve().parent\n",
    "data_dir = proj_dir / 'data'\n",
    "train_imgs_dir = data_dir / 'all_labels/type_1/imgs'\n",
    "train_masks_dir = data_dir / 'all_labels/type_1/masks'\n",
    "image_paths = sorted(list(train_imgs_dir.glob('*.png')))\n",
    "mask_paths = sorted(list(train_masks_dir.glob('*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to go from a path to tensor use `torchvision.transforms.ToTensor()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = ToTensor()(Image.open(image_paths[0]))\n",
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stack many images, use `torch.stack` (not the most memory efficient but it's ok):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorizer = ToTensor()\n",
    "x_tensor = []\n",
    "y_tensor = []\n",
    "\n",
    "for image_path, mask_path in zip(image_paths, mask_paths):\n",
    "    # load an image into a tensor and store in x_tensor, hopefully not too big:\n",
    "    image_tensor = tensorizer(Image.open(image_path))\n",
    "    mask_tensor = tensorizer(Image.open(image_path))\n",
    "    \n",
    "    x_tensor.append(image_tensor)\n",
    "    y_tensor.append(mask_tensor)\n",
    "\n",
    "x_tensor = torch.stack(x_tensor)\n",
    "y_tensor = torch.stack(y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([161, 3, 256, 256])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `torch.utils.data.random_split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115, 113, 147, 107, 116, 139, 17, 108, 128, 3, 148, 137, 143, 135, 62, 2, 33, 118, 42, 111, 34, 144, 1, 41, 5, 28, 106, 72, 69, 51, 124, 50, 103, 29, 157, 79, 67, 45, 80, 15, 37, 43, 76, 100, 0, 8, 89, 81, 95, 75, 159, 150, 20, 145, 25, 102, 54, 88, 141, 60, 120, 23, 112, 52, 85, 10, 53, 7, 155, 49, 73, 83, 68, 39, 4, 27, 47, 9, 142, 12, 55, 19, 133, 160, 110, 154, 87, 152, 97, 138, 117, 74, 71, 130, 101, 30, 22, 134, 91, 64, 156, 61, 70, 122, 35, 11, 26, 94, 149, 66, 136, 93, 59, 92, 18, 132, 123, 46, 48, 21, 36, 114, 158, 57, 38, 105, 127, 125]\n",
      "[119, 31, 78, 90, 65, 99, 82, 126, 40, 77, 32, 16, 44, 109, 104, 146, 140, 6, 98, 14, 129, 151, 58, 63, 131, 96, 24, 56, 86, 84, 121, 13, 153]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(13)  # Important for consistency\n",
    "N = len(x_tensor)\n",
    "n_train = int(.8*N)\n",
    "n_val = N - n_train\n",
    "train_subset, val_subset = random_split(x_tensor, [n_train, n_val])\n",
    "\n",
    "train_idx = train_subset.indices\n",
    "val_idx = val_subset.indices\n",
    "\n",
    "print(train_idx)\n",
    "print(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = x_tensor[train_idx]\n",
    "y_train_tensor = y_tensor[train_idx]\n",
    "\n",
    "x_val_tensor = x_tensor[val_idx]\n",
    "y_val_tensor = y_tensor[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 256, 256])\n",
      "torch.Size([33, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tensor.shape)\n",
    "print(x_val_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our very simple dataset with transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedTensorDataset(Dataset):\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create **temporary** `Dataset` to extract normalization parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalize(mean=tensor([0.1960, 0.2124, 0.1632]), std=tensor([0.1087, 0.1089, 0.1102]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dataset = TransformedTensorDataset(x_train_tensor, y_train_tensor)\n",
    "temp_loader = DataLoader(temp_dataset, batch_size=32)\n",
    "normalizer = StepByStep.make_normalizer(temp_loader)\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Datasets and Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create **real** `Datasets` and `DataLoaders`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_composer = Compose([normalizer])  # train_composer composer will have augmentations later\n",
    "val_composer = Compose([normalizer])\n",
    "\n",
    "train_dataset = TransformedTensorDataset(x_train_tensor, y_train_tensor, transform=train_composer)\n",
    "val_dataset = TransformedTensorDataset(x_val_tensor, y_val_tensor, transform=val_composer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar_panel",
   "language": "python",
   "name": "solar_panel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
